#+LaTeX_CLASS: sendence-com-article-2
#+SETUPFILE: ~/.emacs.dir/org-html-themes/setup/theme-readtheorg.setup
#+TITLE: Performance Tests in AWS
#+AUTHOR: Markus Fix
#+EMAIL: markus@sendence.com
#+DATE: 2016-07-21
#+DESCRIPTION: Notes on how to run performance tests in AWS
#+KEYWORDS: Sendence, distributed, orchestration, buffy, dagon
#+LANGUAGE: english
#+STARTUP: overview
#+TAGS: PROJECT(p) HOME(h) OFFICE(o) PHONE(t) ERRANDS(e)
#+STARTUP: hidestars
#+LaTeX_CLASS_OPTIONS: [10pt,a4paper,captions=tableheading,headsepline,footsepline]
#+LateX_HEADER: \KOMAoptions{titlepage=true, abstract=true}
#+LaTeX_HEADER: \subtitle{Buffy orchestration}
#+LaTeX_HEADER: \usepackage{paralist}
#+LaTeX_HEADER: \usepackage{amssymb}
#+LaTeX_HEADER: \let\itemize\compactitem
#+LaTeX_HEADER: \let\description\compactdesc
#+LaTeX_HEADER: \let\enumerate\compactenum
#+LaTeX_CLASS_OPTIONS: [captions=tableheading]
#+LATEX: 
#+LATEX: \listoffigures

* Introduction
This document describes how to boot and provision a AWS test system
for Buffy performance testing.


* Prepare Dev Box
** Virtualenv on MacBook
Make sure you have =virtualenv= and =virtualenvwrapper= installed on
your MacBook. You can follow along with the [[http://www.marinamele.com/2014/05/install-python-virtualenv-virtualenvwrapper-mavericks.html][installation guide]]. Do the
following in a shell on your MacBook:
#+BEGIN_SRC sh
brew update
brew upgrade
brew install python
pip install virtualenv
pip install virtualenvwrapper
mkdir ~/.virtualenvs
#+END_SRC

Add this to your =.bashrc= file:
#+BEGIN_SRC sh
export WORKON_HOME=~/.virtualenvs
source /usr/local/bin/virtualenvwrapper.sh
#+END_SRC

** Install JQ
#+BEGIN_SRC sh
brew install jq
#+END_SRC

** Install Terraform
#+BEGIN_SRC sh
brew install terraform
#+END_SRC

** Create Ansible Vault
Get the vault password from your friendly sysadmin and echo it into
the vault password file.
#+BEGIN_SRC sh
echo "<XXXXXXX>" > ~/.ansible_vault_pass.txt
#+END_SRC

** Install Ansible and Boto
#+BEGIN_SRC sh
pip install --upgrade setuptools --user python
pip uninstall ansible
pip uninstall boto
pip install -Iv ansible==2.0.0.2
pip install -Iv boto==2.39.0
#+END_SRC

** Boto AWS Credentials
Create a file =$HOME/.boto= with this contents (using your AWS access
keys in place of the =xxx=):
#+BEGIN_SRC sh
[Credentials]
aws_access_key_id = xxx
aws_secret_access_key = xxx
#+END_SRC

** AWS Credentials
Create a directory for AWS credentials.
#+BEGIN_SRC sh
mkdir $HOME/.aws
#+END_SRC

Login to the AWS web console: https://sendence.signin.aws.amazon.com/console
1. Select "Identity and Access Management" from the list of AWS services.
2. Select "Users" form the menu. 
3. Search for your username and select it.
4. Click on "Create Access Key".
5. Click on "Download Credentials".
6. Open the downloaded file named =credentials.csv= in a text editor.

The file you're editing is formatted like this:
#+BEGIN_EXAMPLE
User Name,Access Key Id,Secret Access Key
"markus",AKIAI4W7TVYRVTMQXXXX,pFc6lBX4bSx7HFHG736Ur1B1oRpRCL82xphBXXXX
#+END_EXAMPLE

Edit it too look like this:
#+BEGIN_EXAMPLE
[default]
aws_access_key_id = AKIAI4W7TVYRVTMQXXXX
aws_secret_access_key = pFc6lBX4bSx7HFHG736Ur1B1oRpRCL82xphBXXXX
#+END_EXAMPLE

Save the file into the directory =$HOME/.aws= and name it =credentials=.

** AWS CLI Tools
Install the AWS command-line tools:
#+BEGIN_SRC sh
brew install awscli
#+END_SRC

Test your AWS credentials:
#+BEGIN_SRC sh
aws ec2 describe-instances
#+END_SRC

** AWS SSH Certificate
To login to EC2 instances created by the makefile you need to install the SSH certificates for each region. The example below shows how to do that for the use-east-1 region.
#+BEGIN_SRC sh
mkdir $HOME/.ssh/ec2
cp us-east-1.pem $HOME/.ssh/ec2/us-east-1.pem
#+END_SRC
Ask you friendly sysadmin to provide those =.pem= files.

** Github Personal Access Token
*Please make sure to give the token only minimal privileges!*

(tbd: explain what the above means)

We need to create a Personal Access token for Github. We will use the
token when checking out the Buffy sources from Github.
Open [[https://github.com/settings/tokens][https://github.com/settings/tokens]] and create a token named
=Buffy-AWS-perf-test-token=. Make sure you copy the token string and
save it in a secure place.

Create a new file named =~/.buffy-aws-perf-test-token= with the
following lines:
#+BEGIN_EXAMPLE
[user]
        name = <your name>
        email = <email address used on Github>
[github]
        user = <your github username>
        token = <your token>
#+END_EXAMPLE

We will copy this file to your test box later in this guide.

* Prepare Test Node
Checkout the buffy repository locally (on your dev box).
#+BEGIN_SRC sh
git clone https://github.com/Sendence/buffy.git
#+END_SRC

Boot and provision a single c4.4xlarge EC2 node using spot pricing.
#+BEGIN_SRC sh
cd buffy/orchestration/terraform
make cluster num_followers=0 leader_instance_type=c4.4xlarge
#+END_SRC

Result:
#+BEGIN_SRC sh
PLAY RECAP *********************************************************************
54.209.159.121             : ok=44   changed=23   unreachable=0  failed=0
#+END_SRC

If you want to later destroy the node/cluster just run this command in
the =buffy/orchestration/terraform= directory:
#+BEGIN_SRC sh
make destroy
#+END_SRC

If you run into trouble during the provisioning phase (or see any
errors after logging into the test box) you can try to run the
provisioner again:
#+BEGIN_SRC sh
make configure
#+END_SRC

Copy the Github credentials to the test node:
#+BEGIN_SRC sh
scp -i ~/.ssh/ec2/us-east-1.pem \
 ~/.buffy-aws-perf-test-token \
 ubuntu@54.209.159.121:~/.gitconfig
we #+END_SRC

Login to the node:
#+BEGIN_SRC sh
ssh -i ~/.ssh/ec2/us-east-1.pem ubuntu@54.209.159.121
#+END_SRC

Clone Buffy:
#+BEGIN_SRC sh
git clone https://github.com/Sendence/buffy.git buffy
#+END_SRC

We are using the pre-build ponyc container to build the binaries:
#+BEGIN_SRC sh
cd buffy
make arch=amd64
#+END_SRC

Build the container images if you intend to use them later:
#+BEGIN_SRC sh
make arch=amd64 build-docker
#+END_SRC

This will build the container images and publish them to the local Docker registry.
If you want to publish the resulting images to the Sendence registry you will need to run he publish command:
#+BEGIN_SRC sh
make arch=amd64 push-docker
#+END_SRC

* Run Performance Tests
** Run as Processes
We will use the simple =double-divide.ini= configuration to demonstrate the boot process.
#+BEGIN_SRC sh
cd dagon
./dagon -d -t 10 --filepath=double-divide.ini --phone-home=127.0.0.1:8080
#+END_SRC


** Run as Containers
*** Preparations
While logged in on the test node get the IP address of the main ethernet interface:
#+BEGIN_SRC sh
ifconfig |grep -A 2 ens3
#+END_SRC

Result:
#+BEGIN_EXAMPLE
ens3      Link encap:Ethernet  HWaddr 06:61:0e:2f:98:b1
          inet addr:10.0.28.248  Bcast:10.0.31.255  Mask:255.255.224.0
          inet6 addr: fe80::461:eff:fe2f:98b1/64 Scope:Link
#+END_EXAMPLE

Our internal (VPC) IP address for the test node is =10.0.28.248=.

The ethernet interface names depend on the EC2 instance type. In case the command above does not yield an IP address use this:
#+BEGIN_SRC sh
ifconfig |grep -A 2 eth
#+END_SRC

Copy the =docker-double-divide.ini= configuration file to =/tmp= before starting the test. Copy the =count-to-hundred.txt= data file to =/tmp= if you want to read the numbers from a file (optional):
#+BEGIN_SRC sh
cp dagon/docker-double-divide-aws-leader.ini /tmp
cp dagon/count-to-hundred.txt /tmp #optional
#+END_SRC



*** Boot Metrics-UI (optional)
Pull the Docker image for the UI from the Sendence registry:
#+BEGIN_SRC sh
docker pull docker.sendence.com:5043/buffy-metrics-ui
#+END_SRC

Boot the metrics UI:
#+BEGIN_SRC sh
docker run -d -u 1000 \
 -p 0.0.0.0:4000:4000 \
 --name mui -h mui --net=buffy-leader \
 docker.sendence.com:5043/buffy-metrics-ui
#+END_SRC

*** Boot Metrics-Receiver
Start the metrics receiver:
 #+BEGIN_SRC sh
docker run -d -u 1000 \
 --name metrics  -h metrics  \
 --privileged \
 -v /usr/bin:/usr/bin:ro  -v /var/run/docker.sock:/var/run/docker.sock  \
 -v /bin:/bin:ro  -v /lib:/lib:ro  -v /lib64:/lib64:ro  \
 -v /usr:/usr:ro  -v /tmp:/tmp  -w /tmp  \
 --net=buffy-leader \
 docker.sendence.com:5043/sendence/double-divide.amd64:<docker-image-tag> \
 --run-sink -r -l metrics:9000 -m mui:5001 \
 --name double-divide --period 1 -a double-divide-app
 #+END_SRC

*** Boot Dagon
Boot the Dagon container with the =docker-double-divide.ini= config file that defines the topology. Make sure you replace the =<internal IP address>= placeholder with the internal VPC address of the test node. Replace the =<docker-image-tag>= placeholder with the Docker image tag of your build run.
#+BEGIN_SRC sh
docker run -u 0 \
 --name dagon  -h dagon  --privileged  -i  \
 -e LC_ALL=C.UTF-8 -e LANG=C.UTF-8 \
 -e "constraint:node==ip-10-0-28-248" \
 -v /usr/bin:/usr/bin:ro  \
 -v /var/run/docker.sock:/var/run/docker.sock  \
 -v /bin:/bin:ro  -v /lib:/lib:ro  -v /lib64:/lib64:ro \
 -v /usr:/usr:ro  -v /tmp:/tmp  -w /tmp  \
 --net=buffy-leader \
 docker.sendence.com:5043/sendence/dagon.amd64:<docker-image-tag> \
 dagon.amd64 \
 --docker=tcp://<internal IP address>:2375  \
 -t 30  \
 --filepath=/tmp/docker-double-divide-aws-leader.ini  \
 --phone-home=dagon:8080 \
 --tag=<docker-image-tag>
#+END_SRC

* Appendix
** Ponyc Compiler Install


** Edit Remote Files
*** Howto edit files remotely
*** Howto mount a remote file system via SSH
*** Emacs Tramp

** Docker Swarm Cluster
Performance tests using containers on a Docker Swarm cluster on top of EC2 nodes need to optimize the following parameters:
- Use placement groups
- Use high network bandwidth instance types
